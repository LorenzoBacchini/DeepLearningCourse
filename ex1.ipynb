{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b718ac4-2466-44af-b8fd-1be5b2547738",
   "metadata": {},
   "source": [
    "# First steps into Pytorch\n",
    "for more details: https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6173c1ac-e057-46b0-ade9-1ad3c3dd5f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's start by importing the library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5561279-a8a7-4cb5-bc7f-fc18b6f08c20",
   "metadata": {},
   "source": [
    "A <code>torch.Tensor</code> is a multi-dimensional matrix containing elements of a single data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd7b201-e8bf-4a2e-9e0c-596ddfc35dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4]) torch.Size([16, 32, 128, 128]) torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Generate a Tensor of size 2x2x4\n",
    "t = torch.Tensor(2,2,4)\n",
    "t_2 = torch.Tensor(16,32,128,128)\n",
    "t_3 = torch.Tensor(1, 3, 256, 256)\n",
    "# .size() allows to get the size of the tensor\n",
    "print(t.size(), t_2.size(), t_3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1a60cb-21f6-4ff2-a8a9-669029cd94ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a tensor filled with random numbers \n",
    "# from a normal distribution with mean 0 and variance 1 \n",
    "# with the same size\n",
    "t_r = torch.randn(2,2,4)\n",
    "# and a tensor filled with ones\n",
    "t_ones = torch.ones(2,2,4)\n",
    "t_zeros = torch.zeros(2,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fe3992-19ed-4588-ba74-7eb44f8c07d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.1648e-17,  1.6059e-42,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]) tensor([[[ 1.2139,  0.5739,  2.3323,  0.9436],\n",
      "         [-1.4350,  0.8831, -0.9541, -0.7405]],\n",
      "\n",
      "        [[-0.7077, -0.6542,  1.2276,  1.2713],\n",
      "         [ 0.3673,  0.3336,  1.7920,  0.2050]]]) tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]) tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Print the tensors\n",
    "print(t, t_r, t_ones, t_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614832d1-6fbf-4295-83aa-c58fe84b83a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "# To resize a tensor do\n",
    "#t_r.resize_(4,4)\n",
    "#print(t_r.size(), t_r)\n",
    "t_r.resize_(16,16)\n",
    "print(t_r.size())\n",
    "# be CAREFULL with in-place operations like this one\n",
    "# since they will permanently change the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416c3840-81a4-45a0-90fa-856170e37619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# It is better to firstly clone the tensor and then resize it\n",
    "t_c = t.clone()\n",
    "t_c.resize_(2,2)\n",
    "# so that the original one remains untouched\n",
    "print(t.size(), t_c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ecd70b1-dd29-4d5e-841d-d19da891036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([2, 2, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 4]' is invalid for input of size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m t_v1 \u001b[38;5;241m=\u001b[39m t_v\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(t_v\u001b[38;5;241m.\u001b[39msize(), t_v1\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m----> 5\u001b[0m t_v2 \u001b[38;5;241m=\u001b[39m \u001b[43mt_v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[16, 4]' is invalid for input of size 16"
     ]
    }
   ],
   "source": [
    "# An alternative is to use the .view() operator which do not alter the total number of dimensions of the tensor\n",
    "t_v = torch.randn(4,4)\n",
    "t_v1 = t_v.view(2,2,4)\n",
    "print(t_v.size(), t_v1.size())\n",
    "t_v2 = t_v.view(16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdbd8054-a006-4ddb-8226-a12cbbe5fc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]]])\n",
      "tensor([[[64., 64., 64., 64.],\n",
      "         [64., 64., 64., 64.]],\n",
      "\n",
      "        [[64., 64., 64., 64.],\n",
      "         [64., 64., 64., 64.]]])\n"
     ]
    }
   ],
   "source": [
    "# Fill a tensor with a specific number\n",
    "t_ones.fill_(3)\n",
    "print(t_ones)\n",
    "t_ones.fill_(64)\n",
    "print(t_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06315e4c-1183-4723-af84-3788a39de12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7., 8., 9.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# If you want to create a tensor filled with specific numbers just do\n",
    "v = torch.Tensor([7,8,9])\n",
    "print(v)\n",
    "print(v.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce40be-a8fd-4b79-8d69-6c05757a4508",
   "metadata": {},
   "source": [
    "Working with tensors is exactly like working with vectors and matrices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5febd376-8d6b-4be2-bef1-b2a0b8fc3e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 10., 10.])\n",
      "tensor([21., 16.,  9.])\n",
      "tensor([9., 4., 1.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.Tensor([3,2,1]) # a vector\n",
    "# Sum (or subtraction)\n",
    "print(w + v)\n",
    "# Element-wise multiplication (or division)\n",
    "print(w * v)\n",
    "# Square all elements in the tensor\n",
    "w2 = w.pow(2)\n",
    "print(w2)\n",
    "# and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242eeb56-c86b-4c53-9970-c5cdf9f10b6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# tensors need to have the same number of dimensions in order for them to be summed\n",
    "q = torch.randn(2,4,2)\n",
    "p = torch.randn(2,3,2)\n",
    "\n",
    "print(q + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab258c45-71d1-4649-a754-d0d414f2938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n",
      "torch.Size([2, 4]) 2 4\n"
     ]
    }
   ],
   "source": [
    "# Define a 2x4 matrix\n",
    "m = torch.Tensor([[1,2,3,4],\n",
    "                 [5,6,7,8]])\n",
    "print(m)\n",
    "print(m.size(), m.size(0), m.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc7b8b6c-0a76-4529-b61d-02bde8ef10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.)\n",
      "tensor([3., 7.])\n",
      "tensor([5., 6., 7., 8.])\n",
      "tensor([[3., 4.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Get a value from the matrix\n",
    "print(m[1,2])\n",
    "# Get a column\n",
    "print(m[:,2])\n",
    "# Get a row\n",
    "print(m[1, :])\n",
    "# Getting an intervall of values\n",
    "print(m[:, 2:])\n",
    "print(m[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fb8aa10-6013-420d-b6c9-f4a8b6c0ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7838, 3.1556, 4.6362, 4.5299],\n",
      "        [4.5223, 6.5733, 6.6022, 7.1151]])\n",
      "tensor([[ 0.7838,  2.3112,  4.9085,  2.1196],\n",
      "        [-2.3886,  3.4401, -2.7846, -7.0789]])\n"
     ]
    }
   ],
   "source": [
    "# like with vectors you can do\n",
    "# Sum (or subtraction)\n",
    "b = torch.randn(2,4)\n",
    "print(m + b)\n",
    "# Multiplication (or division)\n",
    "print(m * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9d001fe-1e5e-47a1-bf93-191a303256f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5.],\n",
      "        [2., 6.],\n",
      "        [3., 7.],\n",
      "        [4., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose a matrix\n",
    "print(m.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d3ab60d-67ba-4b61-b9c5-0dcd9313fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32])\n",
      "torch.Size([4, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "# Flatten a tensor maintaining the same batch size (the first element of the Tensor)\n",
    "m_4_dim = torch.randn(4,8,2,2)\n",
    "print(m_4_dim.view(m_4_dim.size(0), -1).size()) \n",
    "# Rearrange dimensions\n",
    "print(m_4_dim.view(m_4_dim.size(0), 16, 2).size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11892ac-f602-4620-9035-7ae7dfa3cadc",
   "metadata": {},
   "source": [
    "Moving tensors to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1d62c05-de21-4ce0-8686-0e17caeab7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Move tensor to GPU device 0 if there is one (first GPU in the system)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "m_d = m.to(device)\n",
    "print(device)\n",
    "print(m_d.device)\n",
    "\n",
    "m = m.cpu()\n",
    "print(m.device)\n",
    "m = m.cuda()\n",
    "print(m.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc359b97-929e-44d6-9d9c-c77a9f4bffad",
   "metadata": {},
   "source": [
    "Moving tensors to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48d797bd-0782-4b30-a8a3-58a49e703b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3. 4.]\n",
      " [5. 6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# Converts tensor to numpy array\n",
    "m_np = m.cpu().numpy()\n",
    "print(m_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab24323-6f7d-40d5-b649-ca79197b0e0a",
   "metadata": {},
   "source": [
    "Tensors concatenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b765c44-69b4-401a-8ade-846348d2f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n",
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3, 4]]) # 1,4\n",
    "b = torch.Tensor([[5, 6, 7, 8]]) # 1,4\n",
    "\n",
    "# Concatenate on axis 0 -> 2,4\n",
    "print(torch.cat((a, b), 0))\n",
    "# Concatenate on axis 1 -> 1,8\n",
    "print(torch.cat((a, b), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29adb1da-326e-4bdc-bda0-4bc876239fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4521,  0.9707,  1.2488,  0.1841, -1.9038,  1.0861, -0.4629,  1.1709,\n",
      "          0.8174, -0.4928,  1.9464,  0.7625,  0.1279,  0.0952,  0.8903,  1.4029],\n",
      "        [ 0.8303, -0.0769,  2.3003, -2.3154, -0.1178,  0.5294,  1.1793,  0.5984,\n",
      "          1.3857, -0.4394, -1.0718, -0.1150,  0.0428,  0.5702, -0.4651, -0.4504],\n",
      "        [-0.6364, -0.6351, -0.4043, -0.5707, -0.1205,  0.2930, -0.5272,  0.1435,\n",
      "         -0.3641,  1.2122, -1.8301, -1.5816,  0.7431, -1.1127, -0.4414, -0.3965]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.randn(3,4)\n",
    "d = torch.randn(3,12)\n",
    "\n",
    "print(torch.cat((c,d), 1)) # 3, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "749be253-07a4-4c16-a50d-2bd95532d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n",
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Adding and removing dimensions from Tensor\n",
    "r_t = torch.randn(3,64,64)\n",
    "\n",
    "# add a dimension\n",
    "r_t = r_t.unsqueeze(0) # argument is WHERE we want the dimension to be added\n",
    "print(r_t.size())\n",
    "\n",
    "# remove a dimension\n",
    "r_t = r_t.squeeze(0) # argument is WHERE we want the dimension to be removed\n",
    "print(r_t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78438106-1a53-45c1-946c-4bd6070e7d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1: Split a 3 dimensional tensor of dimension 4x64x128 \n",
    "# into 2 tensors of size 4x32x128\n",
    "# and then concatenate them together to get the original size back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ec614-493b-406f-a71f-9800bbf88783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex2: You have two matrices of dimension: 4x256x4 and 4x16x64 \n",
    "# concatenate them together to form a single matrix\n",
    "# of dimension 4x64x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e2ed8-e7d7-44b8-a332-c1b63dccc3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ex3: You have 4 matrixes representing 4 RGB images of dimension 3x128x128.\n",
    "# Create a grid of dimension 3x256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cada5-870a-4373-a582-a763e9d880c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
