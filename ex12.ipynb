{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f4101c-0ee4-4bc7-8c15-410a2fac5a7c",
   "metadata": {},
   "source": [
    "# Visualizing Training Statistics with Tensorboard\n",
    "PyTorch integrates with TensorBoard, a tool designed for visualizing the results of neural network training runs.\n",
    "\n",
    "In this tutorial, we’ll learn how to:\n",
    "\n",
    "- Set up TensorBoard.\n",
    "\n",
    "- Write to TensorBoard.\n",
    "\n",
    "- Inspect a model architecture using TensorBoard.\n",
    "\n",
    "- Use TensorBoard to create interactive versions of the statistics visualizations (like loss, accuracy, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2055d69c-bfa4-4492-8eaa-9a936e5d5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\miniconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    img = img.cpu()\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    \n",
    "    to_pil = transforms.ToPILImage()\n",
    "    \n",
    "    if one_channel:\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(to_pil(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4dc907-e72e-4ff7-ae93-235f51aac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a18ba83-406d-4730-a830-dd7dd5df1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa26b0-1d7b-427b-82ea-5bd771ff592e",
   "metadata": {},
   "source": [
    "Now we’ll set up TensorBoard, importing tensorboard from <code>torch.utils</code> and defining a <code>SummaryWriter</code>, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4448f4c-13c0-4c51-b78d-d360a0dd6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('./runs/fashion_mnist_experiment_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd04fa-907f-4bcb-9e71-90d61e32c812",
   "metadata": {},
   "source": [
    "Now let’s write an image to our TensorBoard - specifically, a grid using <code>make_grid</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60810f77-e4e0-4982-90da-1856914b28d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn8UlEQVR4nO3deXRU5f0G8CcBsihkMMEkxBCIigKyiAFCxD1RpFZRUJHSikuPW7Aspwq0gqcujWKtiixaj5VaRSytQKEiYoBQbIAQFsFAQEETCAkgZGFJiOT+/miZn+8zY24mmWRukudzDuf0m5nM3Lz3zvh23me+b5BlWRZEREREHCA40AcgIiIicpYmJiIiIuIYmpiIiIiIY2hiIiIiIo6hiYmIiIg4hiYmIiIi4hiamIiIiIhjaGIiIiIijqGJiYiIiDiGJiYiIiLiGI02MZk9eza6deuGsLAwJCcnY+PGjY31VCIiItJCBDXGXjkffvgh7r33XrzxxhtITk7Gq6++ioULFyI/Px/R0dG1/m5NTQ2KiorQoUMHBAUF+fvQREREpBFYloWKigrExcUhOLj+n3s0ysQkOTkZAwcOxKxZswD8d7LRpUsXPP7445gyZUqtv7t//3506dLF34ckIiIiTaCwsBDx8fH1/v22fjwWAMDp06eRm5uLqVOnun8WHByMtLQ0ZGdne9y/qqoKVVVV7vrsPOm5555DWFiYvw9PREREGkFlZSWeeuopdOjQoUGP4/eJyZEjR3DmzBnExMQYP4+JicGuXbs87p+RkYHf/e53Hj8PCwtDeHi4vw9PREREGlFDYxgB/1bO1KlTUVZW5v5XWFgY6EMSERGRAPH7JyadOnVCmzZtUFJSYvy8pKQEsbGxHvcPDQ1FaGiovw9DREREmiG/f2ISEhKCpKQkZGZmun9WU1ODzMxMpKSk+PvpREREpAXx+ycmADBp0iSMHTsWAwYMwKBBg/Dqq6/ixIkTuP/++xvj6URERKSFaJSJyahRo3D48GFMnz4dxcXFuPzyy/HJJ594BGLr67HHHvPL4zSmoqIio+bvdO/Zs8eoub/LOeecY9T/+c9/jDoqKsqoQ0JCjPrIkSNGffPNN9f6+IEwZ86cWm9vDueZ7d2716i3bNli1JyhOnHihFHzee3evbtRp6amNvQQm1xLPM/iqTme58rKSqN+7733jHrJkiVG3b9/f6Pu1q2bUX/33XdG/emnn9b6/Nw+46qrrjJqJ8Yc7M6zPzTKxAQAxo0bh3HjxjXWw4uIiEgLFPBv5YiIiIicpYmJiIiIOEajLeW0dpwdWLBggVG/+eabRj158mSjLisrM+rly5cb9c6dO436pz/9qVHfddddRp2bm2vUV199tbfDFh/xN822bdtm1JzlOX36tFHX1NQY9ZkzZ4za5XIZdWRkZK23f/7550bN2SZvO1BoTyppifg9EwDGjx9v1Jz1Y23atDHqZcuW+XQM/Nrq2LGjUaelpdX6++edd55RP//880b96KOP+nQ8zYU+MRERERHH0MREREREHEMTExEREXEMZUwayYoVK4y6tLTUqEeNGmXU3P/i448/Nuo+ffoYdY8ePYyaswe8YeKwYcNqP2CpEz4vnN0ZPHiwUR8+fNio+TrgzAevSXPvH86UrF271qi3b99u1P369av18UVaitGjRxv14sWLPe7D/aJ69uxp1Pz6aN++fa01Z8T49zlTxn1T2rY1/xPM2cKqqiqj5oxMdna2Ub/77rtoCfSJiYiIiDiGJiYiIiLiGJqYiIiIiGMoY+InBQUFRs1ZAO4zkpeXZ9Tl5eVGzRkUXpu84YYbjDo+Pt6o//rXvxr1woULjbp3795obezyHN5wL4QJEyYY9aBBg4y6a9euRs1ryJz9iYuLM2rOpJw6dcqor7zyylrrZ5991qhnzpxZ6/OJNFdHjx416tWrVxs15/AA4Pvvv6+15kwH96MqLi6u9fc5U8I4k3LuuecadXh4uFG3a9fOqHv16mXU//rXv4x6//79Hs/J/21oDvSJiYiIiDiGJiYiIiLiGJqYiIiIiGNoYiIiIiKOofCrn/Dma/379zfq48ePG/WhQ4eMukOHDkbNgSUONfHmThEREUZ9ySWXGPU333zj5ahbl7qEXWfNmmXUHB7l81JRUWHUvCkYh185FM3hNw45X3zxxUZdVFRk1Hzd8fOlpqYa9aeffgrWpUsXo65PSFikqfG1zMFTDqYCnmFyDrfyJnscRg0JCTFqfv1yo0t+/PPPP9+ov/vuO6PmBom8CSi/3vm1+cEHH4A98cQTHj9zOn1iIiIiIo6hiYmIiIg4hiYmIiIi4hjKmPgJrwVyhoTXAjlTwg3WuNEWN+Zh3GyIsw+xsbG1/n5LZJeV4PVaAPjHP/5h1NzQiBse8Tp2SUmJUVdXVxs15znatGlj1JwRueaaa4x68+bNRh0aGmrUvMkY/40TJ04E+/vf/27UypT4nrPx9f7cyIt/PywszO4Qfcb5igMHDtT6nFFRUUbNeYtA27lzp1HX5brlTTRvvvlmo54xY4ZRv/LKK0Y9ffp0o161apVRBweb/1//5MmTRs0ZMT4H69atM2p+PXvLzfzQ7t27a729udAnJiIiIuIYmpiIiIiIY2hiIiIiIo6hjImf2G0GxVkDXovcu3evUfNmb7wJIH//ndeD+fn69evn7bBbtaVLl3r8rKyszKijo6NrfQy+nbM8nBnhLFCnTp2Mms8r90XhPgl8HXEfFL4ueM1bvPN3zqawsNCo//znPxs19yXizRm5/83nn39u1Jw92rZtm8cx3H333UbNuTXOO/zkJz8xas47cS6mqXGOj/8ebxky7kPCuZqMjAyjzsnJMerJkycbNb9fMO5fxRk0/u8GXwd8vJw9ZMeOHav19uZCn5iIiIiIY2hiIiIiIo6hiYmIiIg4hjImfsJribx2yOuxvD6am5tr1LzXDq+X8vfhec8G7lnAe0C0BnY5gbffftv2MXgNmTMh3H+GMyXcp4TPE2dOuC8Jn3feD4SvK84iML7uAODgwYNG3blz51ofQzzZXWucVeD+FF27djXqDz/80KgXLlxo1Hze+brhrAIAJCQkGDXnK/gx+dp1Gs7tMM5bAZ7vgx999JFR8+udM1x5eXlGzXtZ8d44X3/9tVHzeeJ+Vpwh4+PhHA1fd/x8zZU+MRERERHH0MREREREHMPnicnatWtx6623Ii4uDkFBQVi8eLFxu2VZmD59Ojp37ozw8HCkpaV5fOVRRERExBufMyYnTpxAv3798MADD2DEiBEet8+YMQMzZ87EX/7yFyQmJmLatGkYOnQo8vLyGmX/B6fgPVQ4S/DFF18Y9b///W+jvv7664365ZdfNurk5GSjnjVrllHHx8cbNa9Feltzbu14nR/w7BvAmQzOkMTExBg1r9Nz1ofXrPk88Z5LnFXidX9+fM688P4m3npPbNy40aiHDx/ucZ/Wzq5nB6/183nbvn27UfN1wDmfAQMGGPWmTZuMmvsUcZ7iiiuu8DhGfo8qLi42ar52+DlYoPdU2r9/v1HzmHIvKW8/42zPL3/5S6Nev369Ud92221GvWDBAqNOS0sz6nfffdeoH3744VprzojxeeWaz2lL6WPi88Rk2LBhGDZsmNfbLMvCq6++iqeeesr95vbuu+8iJiYGixcvxj333NOwoxUREZEWza8Zk3379qG4uNiYNbpcLiQnJyM7O9vr71RVVaG8vNz4JyIiIq2TXycmZz8a5I+3Y2JiPD42PCsjIwMul8v9j7eFFxERkdYj4H1Mpk6dikmTJrnr8vLyZjk54bU+XpPmjAdnULjHAGcDGPcxueSSS4yaswr8fOLZewbwzAZwX4ItW7YYdWpqqlHzXjS8Ds99SXgd365PCdd83XEfA87EeMvVKGNij8+jXeaE97ri64Jf74w/OebzzNkn7o9x2WWXeTxmRUWFUXMmg/9Gp396XVpaatR2rxXA/vXF/aO4vxT/n25+X+U+R7zf0KWXXmrUl19+uVHzXll2552Ph/fiaa78+onJ2Q3MeHBKSko8Njc7KzQ0FBEREcY/ERERaZ38OjFJTExEbGwsMjMz3T8rLy/Hhg0bkJKS4s+nEhERkRbI56Wc48eP46uvvnLX+/btw9atWxEZGYmEhARMmDABzz33HLp37+7+unBcXBxuv/12fx63iIiItEA+T0w2bdpk9Nw4mw8ZO3Ys5s2bhyeffBInTpzAQw89hNLSUlx11VX45JNPWnQPE8BzLZD3POBsAa85Dxw4sNbHT0xMNGpe2+RsBD+fMiaePUO8ZUx43AoKCoyas0J8f+6TwNe93V4XvObNt/Pjc26A+2X06dPHqDmLAAC7d+/2+JmY7M4L387fQuSlbH6/OHz4sFHzdcPZBG5ayXuudOvWDYz7fnAOjfdI4ufgfAb3/GlqnMfgPJW3jAnfh1+PU6ZMMWrO8i1atMioeSXgtddeM+rNmzcb9Zw5c4yazwFHGex6tfDf4613S3Pk88TkuuuuqzX4FRQUhGeeeQbPPPNMgw5MREREWh/tlSMiIiKOoYmJiIiIOEbA+5i0FLyHCfen4LXBrVu3GnXPnj1rfXzeC8euJwFnIXgtsjXiJn+FhYUe9+nevbtRc6+Eb775xqh5TZczHHxeeG8bPi98Hdn1PeFsAW8XwevwvKYNwAizS/3s2LHDqLllAme87M5rWVmZUXNGha/DW2+91ai9vd752uP3CL42OF/B+7BwD42mxn8PH7+3vAWPM9+H98bhHE2PHj1qPSbue8RZn6NHjxo1v945u8QZGDveYhZ271FOpE9MRERExDE0MRERERHH0MREREREHEPBAz/htUheO+S1P15zjo6OrvXx+f68Bs2Pz3vtBLrngBNwbwhvvWN4DZqzAD/72c+Mms8Dr99WVlYaNfeC4CwAPx/j3iucTerYsaNRv//++0bNvSoAz94n/Bze9tfxJ7seIY39+94eg2vOCvF5Xb16tVFzPwruM8SvR74O+G/g88p5il69ehk1X5eAZ6aE80l87fF551xLoDMmfI7q0tODz9sdd9xh1Ly3zccff2zU/L7KPYC4rwmfN87t8PvF4sWLjZozJnbvD96ufc4jKmMiIiIi4gNNTERERMQxNDERERERx1DGxE943Y7XIu3WBu36jPB6MOcAeA2bsxLi2TvG23f+uV/MmjVrjPqtt94y6ocfftioDxw4YNQul8uoOavA542PiXMx3LuB+yQsW7as1uNJSkoCGz16tFFzL4bGzpjUJxNSm9q2zKjrc/J5Yp9++qlR2+Uz+LxxXV5ebtScUeO8xODBg42a8yPeMiYJCQlGbTcGUVFRRn3w4MFa79/Y+D2PzzPndrjvCuCZ+eDH5Cwf9zq66KKLjJr7BHGfEn4t8THx8fDvc1aJ+yoxb9c+X2vNgT4xEREREcfQxEREREQcQxMTERERcQxlTPyE16T5++d79uwx6sjISJ8e367/hd2auADZ2dlGnZOT43Gf/fv3GzWPO/eP4B4giYmJRt2uXTuj5uwPPz5niXjNmH+f16i5r8nXX39t1N6uOz5GzhIEul+FHbushLd1d86EcKaD5ebmGvWRI0eMmvMbnE3grNDJkydrfT526NAho7766quNml//nJUCPHMnPAZ8bXNOjvMPTY2vy/r0r+HXC/cpmTt3rlHzuPKYXHnllUa9ZMkSoy4oKKj1GDmLxLkePl7OInFGzRv+neZA/zUTERERx9DERERERBxDExMRERFxDE1MRERExDEUfm0kHGrkzaP69Onj0+NxI61du3YZNYegONAons2QeOMzwDModsstt9T6mDt37jTq3r17GzU3cOLwG4dZ+bxxYy1upMWh6vvuu8+o3377baNesWIFGIcKb7zxRqO+/PLLPX6nMdWlQVpt9+cx9haKtAu7bty40ai/+OILo+YQJIcc+fXOYXVuesXHw4FjPu8cmuTn89ZUi5t92W0Qx/fnuqnxdVqfxnxdunQx6uLiYqPm1w+/Z5SUlBg1XwepqalGvWnTJqO+4oorjDorK8uoORTdvXt3o+YN+Q4fPmzU3sZE4VcRERGRBtDERERERBxDExMRERFxDGVM/ITXa7kxD9dffvmlT49/4YUXGvWqVauMmrMIjb3xWnPEDaK8NSfijEenTp2Met68eUZ9/vnn1/qYnH/gmteUORvA1w1nD/g6SEtLM2pec+ZNBQHPa5fzDI2tPo2yGnJ/wLPZGGcBODvEja/qci39EDe240Z6nAPo2rWrUXNWiWv+e7xtYMc5FL62uGkc52J4gzt+z2ls/DfxeefXTlxcnMdj8Pvo5s2bjbpfv35GvWPHDqO+4YYbjJozXnfddZdRc6aFG7KtX7/eqL2dtx/i16ZdAzeg6c+TP+gTExEREXEMTUxERETEMTQxEREREcdQxsRPuA8Brxnzei5/P94Or/fymnd+fr5R84ZcAmzbts2oeYMswLMvAWc6tmzZYtS8hsxZA17f5euAs0CcHeDb7X6fNybkDIw3fK3WJ7PREHbPV1paatScleBzxmPIOQLAsx8EZz64bxCfV7vNFvlv4kwKZ05CQ0ONmjNo/Dcz7kHiLV8RHR1t1Hxt8EaDPK7cx4R78DS2AwcOGDWPMfeOuuyyyzwewy77t3LlSqPm99WQkBCjzsvLM2p+X9+7d69RcxbI7nj4b+K+Jtxvxxt+zuZAn5iIiIiIY/g0McnIyMDAgQPRoUMHREdH4/bbb/eYUVZWViI9PR1RUVFo3749Ro4c6dEtT0RERMQbnyYmWVlZSE9Px/r167Fy5UpUV1fjpptuMj7imzhxIpYuXYqFCxciKysLRUVFGDFihN8PXERERFoenzImn3zyiVHPmzcP0dHRyM3NxTXXXIOysjK8/fbbmD9/vvv73u+88w569uyJ9evXY/Dgwf47cofhtcHPPvvMqHndOyUlxafH57VKXnP+6quvjLpz584+PX5rwHkPb+v2ERERRs09Pni/Ds542O1ZZJc5sdtLhx+fcwD86eSll15q1LxO7+05+W9uapmZmUb99ddfGzX3omA8ppzHAjzzFpwB4Zp7ZHD/GbvzzpmUQ4cOGTXvecK5H85/cJ8TzlNwJg2wv/75b+QcDh8T7wvV2LjPCudy+O/hMQc8x4CzPrwnEvvggw+Mms8z59j4vHEfJD5G7jPka+bM22uX80fNQYMyJmdDNWdPbm5uLqqrq40mTz169EBCQgKys7Mb8lQiIiLSCtT7Wzk1NTWYMGEChgwZ4p45FxcXIyQkxOPbDjExMR67OJ5VVVVlzGKb406IIiIi4h/1/sQkPT0dO3bswIIFCxp0ABkZGXC5XO5//PVLERERaT3q9YnJuHHjsGzZMqxduxbx8fHun8fGxuL06dMoLS01PjUpKSlBbGys18eaOnUqJk2a5K7Ly8ub5eSE1/q2bt1q1NxXhHsC8Bo1rxHzJ068VsoZlKbe76Q54DHl3hOAZ4aE17E5W8B4PZefkzMjdo/P6/58HfHz8Zo396r49ttvPY6ZczVNvSbN1/6uXbuMmo+H+5pwRobHnHsMAUBRUZFR81o+94/g23ktn7M+XO/bt8+oOWPCfUc4G8Q197PgfAXvwQJ47nXD+Qfu0cHvaayp+91w7oePl18rfF0Dnq8vvjb4Mfk8c8bDbo80xrfz+ziPKR8v91Xi5/d2TuyOyYl8OmLLsjBu3DgsWrQIq1atQmJionF7UlIS2rVrZ4TX8vPzUVBQ8KNhz9DQUERERBj/REREpHXy6ROT9PR0zJ8/H0uWLEGHDh3c/y/e5XIhPDwcLpcLDz74ICZNmoTIyEhERETg8ccfR0pKSov+Ro6IiIj4h08Tk7lz5wIArrvuOuPn77zzDu677z4AwCuvvILg4GCMHDkSVVVVGDp0KObMmeOXgxUREZGWzaeJibc1eRYWFobZs2dj9uzZ9T6o5ojX9rgHAK9dctaA788ZEd6DgdcmeT+EO+64w+aIWz5ef+WcgLdlQ8588Hngb43xmjOvWfvaE4Sfn68LPu/8fJw1sLsd8MwecOajsXHe6uKLLzZqzmNwPoSPl19bdvvMeMOvV7t80rFjx4z6m2++MeqEhASjTk1NNWruX8G9Wrz15Pghvk64Twvgeb3ztczXKmd7+FoKdMaEMzKcPfL2KT3vhWP3euIx4fNudzuPEWfAGGeb+BwkJSXV+nzeBLovUX00v1SMiIiItFiamIiIiIhjaGIiIiIijlHvzq9SO84K8Noh47VOtn//fqPmdUN+fO5f0RrxmHCfA84RAJ59AwoKCoya8wvcr4LxGjH3FODn48yK3ePx38hrzpwf4THwdp+6rFv7E/8NnJfgHkhc22VKvGVM+Hf4vHAeg8eIswicc+H8A2dUOEfT0NerXaYN8Lx2OP9g18PDLu/U2DiL5K0/zQ8NGjTI42e83xvztsfQD9llSJhdDxG75+PrirNKddHUr2d/0CcmIiIi4hiamIiIiIhjaGIiIiIijqGMSSPhPgJHjhyp9f5264CcdeC9NXgtUhkTz+yC3Zo04Ln2z+vonB3gLMLhw4eNmtf1+TxzFol35rbrS8K/z8/HmRVv2QNe527qvXL4Wh0+fLhRc/8K3s+I+1fwmHjrAcLZAM4CcL7Crq8J72HE1w3vcWL3+rR7P+Dj5347nEkDPPvBcD7KLsPBY2CXm/M3u74q7JJLLvH4GWeFGtqnxO614msGhZ+P+1PxNjB16SXD2aDmQJ+YiIiIiGNoYiIiIiKOoYmJiIiIOIYyJo2Eswi8fstri3Zryrz3Bu+lwevFvKbdGnGvip49exq1tz0kOJOxbds2o+Z1dV7L574knHfgLBAfA2cTeH2Y19V5jTsnJ8eoec8kvi4BICoqyqh5Xbux8bXP+4nwtWx3bfOYeMsB8Hng+/DtdhkTfj3b7YnCfM2UMH79Dxw40OM+nFeyew+yu93Xv7Gh+Lq029PJ2+2cs+G8Er/e7DJijM+TrzW//vk9jDNtfDycNQI83xPObrjrZPrERERERBxDExMRERFxDE1MRERExDGUMWkkvBbIa4dccy8G7lNy7Ngxo+a1T17vrUvPjpbO2x4pdriPCffA4PVazmzY9U7hOjIy0qi5/w3/DZxt4OwS76XRt29fo+Y+DoBnPqGp90CpSy8GX9iNOeC9n0sg+XsMvD2e3b5OTsfHz68N7iXDNQBkZmYa9YYNG4ya92Gyy5hwDsfX88jv25wp4b5GrFevXkZdVFTkcZ/i4mKfjskJ9ImJiIiIOIYmJiIiIuIYmpiIiIiIY2hiIiIiIo6h8GsjueCCC4zaLmxn17inf//+Rs2hK28blbV23CyJm53xhnsAMGrUKKO+7rrr/H5cTYkbvr300kse9+GgNgfwRJyAg+G8uSMHRe2CowBw7bXXNvSwAopfq/wlCsAzIN8c6BMTERERcQxNTERERMQxNDERERERx1DGpJG4XC6j5nW+8vJyo+bN4Ljx1ueff17r83nbqKy14+Zne/bsMWpvuZ4BAwY06jE1NW4y1alTJ4/7bN++3fY+IoE2bNgwoz5+/LhR8wac3t4T7TbB9HejO1/xe5Jdo8zx48cb9b59+zzuc+ONNzb8wJqYPjERERERx9DERERERBxDExMRERFxDGVMGsn1119v1Jxv4M3e+P7c94Q3n1qzZo1RDx06tD6H2aJ169bNqJcvX27U3voc8Dp1Q/GacaDXsHlNGgCWLFli1I888khTHY5InXGPIa7ro7lvdpqenh7oQ2gU+sREREREHMOnicncuXPRt29fREREICIiAikpKcb/C62srER6ejqioqLQvn17jBw5EiUlJX4/aBEREWmZfJqYxMfH44UXXkBubi42bdqEG264AcOHD8eXX34JAJg4cSKWLl2KhQsXIisrC0VFRRgxYkSjHLiIiIi0PEGW3SYtNiIjI/HSSy/hzjvvxPnnn4/58+fjzjvvBADs2rULPXv2RHZ2NgYPHlynxysvL4fL5cIf/vAHhIeHN+TQREREpImcOnUKv/71r1FWVuaxB5cv6p0xOXPmDBYsWIATJ04gJSUFubm5qK6uRlpamvs+PXr0QEJCArKzs3/0caqqqlBeXm78ExERkdbJ54nJ9u3b0b59e4SGhuKRRx7BokWL0KtXLxQXFyMkJMTjmw4xMTEoLi7+0cfLyMiAy+Vy/+vSpYvPf4SIiIi0DD5PTC699FJs3boVGzZswKOPPoqxY8ciLy+v3gcwdepUlJWVuf8VFhbW+7FERESkefO5j0lISAguvvhiAEBSUhJycnLw2muvYdSoUTh9+jRKS0uNT01KSkoQGxv7o48XGhqK0NBQ349cREREWpwG9zGpqalBVVUVkpKS0K5dO6MRWH5+PgoKCpCSktLQpxEREZFWwKdPTKZOnYphw4YhISEBFRUVmD9/PtasWYMVK1bA5XLhwQcfxKRJkxAZGYmIiAg8/vjjSElJqfM3ckRERKR182licujQIdx77704ePAgXC4X+vbtixUrVri3VX7llVcQHByMkSNHoqqqCkOHDsWcOXN8OqCz316urKz06fdEREQkcM7+d7uBXUga3sfE3/bv369v5oiIiDRThYWFiI+Pr/fvO25iUlNTg6KiIliWhYSEBBQWFjaoUUtrV15eji5dumgcG0Bj2HAaQ//QODacxrDhfmwMLctCRUUF4uLiEBxc/wir43YXDg4ORnx8vLvR2tl9eaRhNI4NpzFsOI2hf2gcG05j2HDextDlcjX4cbW7sIiIiDiGJiYiIiLiGI6dmISGhuLpp59W87UG0jg2nMaw4TSG/qFxbDiNYcM19hg6LvwqIiIirZdjPzERERGR1kcTExEREXEMTUxERETEMTQxEREREcdw7MRk9uzZ6NatG8LCwpCcnIyNGzcG+pAcKyMjAwMHDkSHDh0QHR2N22+/Hfn5+cZ9KisrkZ6ejqioKLRv3x4jR45ESUlJgI7Y+V544QUEBQVhwoQJ7p9pDOvmwIED+PnPf46oqCiEh4ejT58+2LRpk/t2y7Iwffp0dO7cGeHh4UhLS8OePXsCeMTOcubMGUybNg2JiYkIDw/HRRddhGeffdbYf0RjaFq7di1uvfVWxMXFISgoCIsXLzZur8t4HT16FGPGjEFERAQ6duyIBx98EMePH2/CvyLwahvH6upqTJ48GX369MG5556LuLg43HvvvSgqKjIewx/j6MiJyYcffohJkybh6aefxubNm9GvXz8MHToUhw4dCvShOVJWVhbS09Oxfv16rFy5EtXV1bjppptw4sQJ930mTpyIpUuXYuHChcjKykJRURFGjBgRwKN2rpycHLz55pvo27ev8XONob1jx45hyJAhaNeuHZYvX468vDy8/PLLOO+889z3mTFjBmbOnIk33ngDGzZswLnnnouhQ4dq487/efHFFzF37lzMmjULO3fuxIsvvogZM2bg9ddfd99HY2g6ceIE+vXrh9mzZ3u9vS7jNWbMGHz55ZdYuXIlli1bhrVr1+Khhx5qqj/BEWobx5MnT2Lz5s2YNm0aNm/ejI8++gj5+fm47bbbjPv5ZRwtBxo0aJCVnp7urs+cOWPFxcVZGRkZATyq5uPQoUMWACsrK8uyLMsqLS212rVrZy1cuNB9n507d1oArOzs7EAdpiNVVFRY3bt3t1auXGlde+211vjx4y3L0hjW1eTJk62rrrrqR2+vqamxYmNjrZdeesn9s9LSUis0NNT64IMPmuIQHe+WW26xHnjgAeNnI0aMsMaMGWNZlsbQDgBr0aJF7rou45WXl2cBsHJyctz3Wb58uRUUFGQdOHCgyY7dSXgcvdm4caMFwPr2228ty/LfODruE5PTp08jNzcXaWlp7p8FBwcjLS0N2dnZATyy5qOsrAwAEBkZCQDIzc1FdXW1MaY9evRAQkKCxpSkp6fjlltuMcYK0BjW1T//+U8MGDAAd911F6Kjo9G/f3+89dZb7tv37duH4uJiYxxdLheSk5M1jv9z5ZVXIjMzE7t37wYAbNu2DevWrcOwYcMAaAx9VZfxys7ORseOHTFgwAD3fdLS0hAcHIwNGzY0+TE3F2VlZQgKCkLHjh0B+G8cHbeJ35EjR3DmzBnExMQYP4+JicGuXbsCdFTNR01NDSZMmIAhQ4agd+/eAIDi4mKEhIS4L56zYmJiUFxcHICjdKYFCxZg8+bNyMnJ8bhNY1g3e/fuxdy5czFp0iT85je/QU5ODn71q18hJCQEY8eOdY+Vt9e3xvG/pkyZgvLycvTo0QNt2rTBmTNn8Pzzz2PMmDEAoDH0UV3Gq7i4GNHR0cbtbdu2RWRkpMb0R1RWVmLy5MkYPXq0eyM/f42j4yYm0jDp6enYsWMH1q1bF+hDaVYKCwsxfvx4rFy5EmFhYYE+nGarpqYGAwYMwO9//3sAQP/+/bFjxw688cYbGDt2bICPrnn429/+hvfffx/z58/HZZddhq1bt2LChAmIi4vTGIojVFdX4+6774ZlWZg7d67fH99xSzmdOnVCmzZtPL7tUFJSgtjY2AAdVfMwbtw4LFu2DKtXr0Z8fLz757GxsTh9+jRKS0uN+2tM/19ubi4OHTqEK664Am3btkXbtm2RlZWFmTNnom3btoiJidEY1kHnzp3Rq1cv42c9e/ZEQUEBALjHSq/vH/fEE09gypQpuOeee9CnTx/84he/wMSJE5GRkQFAY+iruoxXbGysx5crvv/+exw9elRjSs5OSr799lusXLnS/WkJ4L9xdNzEJCQkBElJScjMzHT/rKamBpmZmUhJSQngkTmXZVkYN24cFi1ahFWrViExMdG4PSkpCe3atTPGND8/HwUFBRrT/0lNTcX27duxdetW978BAwZgzJgx7v+tMbQ3ZMgQj6+q7969G127dgUAJCYmIjY21hjH8vJybNiwQeP4PydPnkRwsPnW3KZNG9TU1ADQGPqqLuOVkpKC0tJS5Obmuu+zatUq1NTUIDk5ucmP2anOTkr27NmDzz77DFFRUcbtfhvHeoR1G92CBQus0NBQa968eVZeXp710EMPWR07drSKi4sDfWiO9Oijj1oul8tas2aNdfDgQfe/kydPuu/zyCOPWAkJCdaqVausTZs2WSkpKVZKSkoAj9r5fvitHMvSGNbFxo0brbZt21rPP/+8tWfPHuv999+3zjnnHOu9995z3+eFF16wOnbsaC1ZssT64osvrOHDh1uJiYnWqVOnAnjkzjF27FjrggsusJYtW2bt27fP+uijj6xOnTpZTz75pPs+GkNTRUWFtWXLFmvLli0WAOuPf/yjtWXLFve3ReoyXjfffLPVv39/a8OGDda6deus7t27W6NHjw7UnxQQtY3j6dOnrdtuu82Kj4+3tm7davy3pqqqyv0Y/hhHR05MLMuyXn/9dSshIcEKCQmxBg0aZK1fvz7Qh+RYALz+e+edd9z3OXXqlPXYY49Z5513nnXOOedYd9xxh3Xw4MHAHXQzwBMTjWHdLF261Ordu7cVGhpq9ejRw/rTn/5k3F5TU2NNmzbNiomJsUJDQ63U1FQrPz8/QEfrPOXl5db48eOthIQEKywszLrwwgut3/72t8abv8bQtHr1aq/vgWPHjrUsq27j9d1331mjR4+22rdvb0VERFj333+/VVFREYC/JnBqG8d9+/b96H9rVq9e7X4Mf4xjkGX9oJ2giIiISAA5LmMiIiIirZcmJiIiIuIYmpiIiIiIY2hiIiIiIo6hiYmIiIg4hiYmIiIi4hiamIiIiIhjaGIiIiIijqGJiYiIiDiGJiYiIiLiGJqYiIiIiGNoYiIiIiKO8X/r1UrwSs66iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f256bd-14ee-40a6-b5c7-4a192e036d18",
   "metadata": {},
   "source": [
    "### Now lets run:\n",
    "<code>tensorboard --logdir=runs</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bd9d6-cc1e-47ac-94cc-a98cd533615d",
   "metadata": {},
   "source": [
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b092e504-a3ca-48dd-ab9d-beee3d5151d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images.to(device))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374bbde-eb0c-438a-b87a-03fe944e3940",
   "metadata": {},
   "source": [
    "## Tracking Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f297e3-aca3-4328-836e-4c3dd93d4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cb570-837c-47af-bf6f-73a669f33392",
   "metadata": {},
   "source": [
    "Finally, let’s train the model using the usual model training code, but writing results to TensorBoard every 1000 batches instead of printing to console; this is done using the <code>add_scalar</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9c5e29-17da-428c-9e5b-01e3c5f649d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# get gradients list for each layer in the network\n",
    "def add_gradient_hist(net):\n",
    "    ave_grads = [] \n",
    "    layers = []\n",
    "    for n,p in net.named_parameters():\n",
    "        if (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            if p.requires_grad: \n",
    "                ave_grad = np.abs(p.grad.clone().detach().cpu().numpy()).mean()\n",
    "            else:\n",
    "                ave_grad = 0\n",
    "            ave_grads.append(ave_grad)\n",
    "        \n",
    "    layers = [layers[i].replace(\".weight\", \"\") for i in range(len(layers))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    plt.bar(np.arange(len(ave_grads)), ave_grads, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=90)\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom=-0.001, top=np.max(ave_grads) / 2)  # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    #plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['mean-gradient', 'zero-gradient'])\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588636ba-7ac5-4b1e-b089-dae09e41444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 999 Loss: 0.9402531315665692 Accuracy: 0.64\n",
      "It: 1999 Loss: 0.6345891732379095 Accuracy: 0.75725\n",
      "It: 2999 Loss: 0.5581337310762611 Accuracy: 0.78475\n",
      "It: 3999 Loss: 0.5288350316276774 Accuracy: 0.8045\n",
      "It: 4999 Loss: 0.4713383136203047 Accuracy: 0.8315\n",
      "It: 5999 Loss: 0.4548171425031323 Accuracy: 0.83775\n",
      "It: 6999 Loss: 0.4468784063796047 Accuracy: 0.8415\n",
      "It: 7999 Loss: 0.44567941377751413 Accuracy: 0.83925\n",
      "It: 8999 Loss: 0.4102792346151837 Accuracy: 0.84725\n",
      "It: 9999 Loss: 0.4182868138799022 Accuracy: 0.8475\n",
      "It: 10999 Loss: 0.41594951701478566 Accuracy: 0.8495\n",
      "It: 11999 Loss: 0.3946758243892691 Accuracy: 0.851\n",
      "It: 12999 Loss: 0.42413519150556384 Accuracy: 0.8525\n",
      "It: 13999 Loss: 0.4059249096950225 Accuracy: 0.855\n",
      "It: 14999 Loss: 0.36139700540318154 Accuracy: 0.8665\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "running_loss = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "# define a function to freeze the model layers\n",
    "def set_conv_parameter_requires_grad(model, req_grad = False):\n",
    "    for n,p in net.named_parameters():\n",
    "        if \"conv\" in n:\n",
    "            p.requires_grad = req_grad\n",
    "\n",
    "#set_conv_parameter_requires_grad(net)\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # put data to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # ...log a Matplotlib Figure showing the model's gradients fo each layer\n",
    "        if i % 1000 == 999:\n",
    "            writer.add_figure('gradients',\n",
    "                            add_gradient_hist(net),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        correct += get_num_correct(outputs, labels)\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            # ...log the training accuracy\n",
    "            writer.add_scalar('training accuracy',\n",
    "                            correct / (1000*inputs.size(0)), # inputs.size(0) is the batch size\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('It: {} Loss: {} Accuracy: {}'.format(epoch * len(trainloader) + i, running_loss / 1000, correct / (1000*inputs.size(0))))\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct = 0.0\n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42480d-f0e1-4de0-9cca-b4041dd38dbf",
   "metadata": {},
   "source": [
    "# Assessing trained models with TensorBoard\n",
    "Let's calculate the precision recall curve of our model.\n",
    "\n",
    "REMINDER:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/720/0*eBNoU76LKUuCS6ap.png)\n",
    "\n",
    "Precision $P$ is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$). Precision can be thought of as the fraction of positive predictions that actually belong to the positive class:\n",
    "$$P = \\frac{T_p}{T_p + F_p}$$\n",
    "\n",
    "Recall $R$  is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$). Recall can be thought of as the fraction of positive predictions out of all positive instances in the data set:\n",
    "$$R = \\frac{T_p}{T_p + F_n}$$\n",
    "\n",
    "The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14f457f-e642-49e2-beee-ebb26a0ea03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el.cpu(), dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels.cpu())\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2792a2-b39f-4a09-b7bb-6e47547fcf26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
