{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc6c4ca-b3f8-4cce-8ee9-24ee3f891766",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "We have already seen how to load a dataset provided by the Pytorch library, but what about custom data?\n",
    "\n",
    "Here we will focus on datasets composed by images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6bb8e-8d7d-40df-97eb-42234ef09627",
   "metadata": {},
   "source": [
    "## Labeled Dataset\n",
    "Dataset comes in the following form: \n",
    "- Main_Folder\n",
    "    - label0\n",
    "    - label1\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d36bc9-c591-4957-85de-2a087110f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d0e669-1843-4d6e-8b59-8724b50cc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly define the transforms that you want to apply to the data\n",
    "data_transform = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037af8a-4ac4-47d7-b93f-c2571131cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder as data loader\n",
    "# It will iterate in the root folder and find all the subfolders that define the labels\n",
    "cats_dogs_ds = datasets.ImageFolder(\n",
    "            root='res/custom_dataset/two_class_dataset',\n",
    "            transform=data_transform) #apply transform when loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc4d92-54f8-484a-a39d-f24c270b8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "labels_map = {\n",
    "    0: \"Cat\",\n",
    "    1: \"Dog\"\n",
    "}\n",
    "figure = plt.figure(figsize=(4, 4))\n",
    "cols, rows = 2, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # select a random index\n",
    "    sample_idx = torch.randint(len(cats_dogs_ds), size=(1,)).item()\n",
    "    # get the corresponding tuple (img, label) from the dataset\n",
    "    img, label = cats_dogs_ds[sample_idx]\n",
    "    # plot the data\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(to_pil(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c1af35-818f-4835-98db-aa277246383a",
   "metadata": {},
   "source": [
    "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
    "\n",
    "DataLoader is an iterable that abstracts this complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302bd17-8f65-4e32-b343-835913bc5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(cats_dogs_ds, # dataset to iterate\n",
    "                              batch_size=2, # how many images to load every iteration\n",
    "                              shuffle=True) # sample data randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0acbc-bd3b-4fa6-87af-c9cfe85c0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate trough the dataloader\n",
    "for i, (img, labels) in enumerate(train_dataloader):\n",
    "    print(\"Loaded images of size {} with labels {}\".format(img.size(), labels))\n",
    "\n",
    "print(\"--------\")\n",
    "# Iterate only once\n",
    "img, labels = next(iter(train_dataloader))\n",
    "print(\"Loaded images of size {} with labels {}\".format(img.size(), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f5c90-7ea3-4877-80d6-dd93aef850bc",
   "metadata": {},
   "source": [
    "## Unlabeled Dataset\n",
    "Images are in a folder and do not have a particular label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a41992-82df-42e0-b8f5-e5f963ceb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Custom Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define a function to load images\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "# Alternative: from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d310852-d05c-404d-8bb4-0046169f65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "class PaintingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.file_list = glob.glob(self.root_dir + \"*.jpg\") # we want only jpg images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    # This function is called every time we iterate the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = self.file_list[idx]\n",
    "        image = pil_loader(img_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe5ef5-3661-4bbf-8524-bc484cda0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "paint_ds = PaintingDataset(\n",
    "            root_dir='res/custom_dataset/unlabeled_dataset/friedrich_paintings/',\n",
    "            transform=data_transform)\n",
    "print(len(paint_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fbf84-2e07-454c-9c25-a7b31d5b0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "figure = plt.figure(figsize=(4, 4))\n",
    "cols, rows = 2, 2\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(paint_ds), size=(1,)).item()\n",
    "    img = paint_ds[sample_idx] # __get_item__() method is called\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(to_pil(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7400691-21b6-4069-91d6-3251624e2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can then iterate the dataset using a DataLoader as before\n",
    "paint_dataloader = DataLoader(paint_ds, # dataset to iterate\n",
    "                              batch_size=2, # how many images to load every iteration\n",
    "                              shuffle=True) # sample data randomly\n",
    "\n",
    "for i, (img) in enumerate(paint_dataloader):\n",
    "    print(\"Loaded images of size {}\".format(img.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62819bb3-ba21-45d8-8ee6-5a4c2278b341",
   "metadata": {},
   "source": [
    "## Custom Dataset are much more than that\n",
    "You can write custom dataset to load dataset that comes with additional information (like keypoints, text, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57717b36-7f20-498e-b76a-a5eb278254b2",
   "metadata": {},
   "source": [
    "### Example: Loading Semantic Masks\n",
    "We want to load image of human faces and the corresponding semantic mask that segment the different parts in the human face (nose, eyes, mouth, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4cfc11-292b-43d4-81f8-5d74f4df0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data\n",
    "img = Image.open('res/custom_dataset/semantic_masks/img/0.jpg')\n",
    "# Show the data\n",
    "mask = Image.open('res/custom_dataset/semantic_masks/mask/0.png')\n",
    "\n",
    "figure = plt.figure(figsize=(4, 4))\n",
    "cols, rows = 2, 1\n",
    "figure.add_subplot(rows, cols, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "figure.add_subplot(rows, cols, 2)\n",
    "plt.imshow(mask)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f0a0e-bd0a-4740-a30e-338f29512aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP', '.tiff', '.webp'\n",
    "]\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "class ImgMaskDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, img_transform, mask_transform):\n",
    "        \n",
    "        # get the files list\n",
    "        self.image_paths = self.get_paths(img_dir)\n",
    "        self.mask_paths = self.get_paths(mask_dir)\n",
    "        \n",
    "        self.img_transform = img_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        \n",
    "        size = len(self.image_paths)\n",
    "        self.dataset_size = size\n",
    "\n",
    "    def get_paths(self, dir):\n",
    "        images = []\n",
    "        for root, dnames, fnames in sorted(os.walk(dir)):\n",
    "            for fname in fnames:\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    images.append(path)\n",
    "        return images\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Label Image\n",
    "        label_path = self.mask_paths[index]\n",
    "        label = Image.open(label_path)\n",
    "\n",
    "        label_tensor = self.mask_transform(label) * 255.0 # mask goes from 0 to 19\n",
    "        \n",
    "        # input image (real images)\n",
    "        image_path = self.image_paths[index]\n",
    "        image = pil_loader(image_path)\n",
    "        \n",
    "        image_tensor = self.img_transform(image)\n",
    "\n",
    "        input_dict = {'label': label_tensor,\n",
    "                      'image': image_tensor,\n",
    "                      'img_path': image_path,\n",
    "                      'label_path': label_path,\n",
    "                      }\n",
    "\n",
    "        return input_dict\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ea7a6-1798-4a48-9e16-0e405e63ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizialize dataset\n",
    "img_transform = transforms.Compose([transforms.Resize((128,128)), # Why no Random Horizontal Flip?\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))])\n",
    "\n",
    "mask_transform = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "img_dir = 'res/custom_dataset/semantic_masks/img/'\n",
    "mask_dir = 'res/custom_dataset/semantic_masks/mask/'\n",
    "\n",
    "img_mask_ds = ImgMaskDataset(img_dir = img_dir, mask_dir = mask_dir, img_transform = img_transform,\n",
    "                             mask_transform = mask_transform)\n",
    "print(len(img_mask_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27939067-48a3-4857-9f04-48ce786fce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)   \n",
    "\n",
    "figure = plt.figure(figsize=(6, 2))\n",
    "cols, rows = 4, 2\n",
    "for i in range(1, cols * rows + 1, 2):\n",
    "    sample_idx = torch.randint(len(img_mask_ds), size=(1,)).item()\n",
    "    data = img_mask_ds[sample_idx] # __get_item__() method is called\n",
    "    \n",
    "    img = data['image']\n",
    "    label = data['label']\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(to_pil(denorm(img)))\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(to_pil(label/255))\n",
    "           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40ab9a-930a-4fa8-b318-1bdb69c19928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1: the folder with path res\\custom_dataset\\attributes_dataset contains: \n",
    "# - a txt file containing face attributes\n",
    "# - a folder \"images\" containing face images\n",
    "# the attribute files is organized as follows: first line is the number of images in the folder \"images\",\n",
    "# second line is a list of attributes names and all the remaining lines describe which attributes \n",
    "# each image has with the following notation ('1' = attribute is present, '-1' = attribute is not present).\n",
    "# Create a custom dataset that, when __get_item()__ is called, returns:\n",
    "# 1) the image data\n",
    "# 2) the attributes of that image organized as a tensor of 1 and 0 values (1 = attribute is present\n",
    "# , 0 = attribute is not present). Example: 1.,1.,0.,0.,...,1.,0.,1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae386a-e1f7-472b-84eb-f193513d3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2: modify the dataset class in order to return only a subset of attributes defined by an array\n",
    "# like [\"Blond_Hair\", \"Heavy_Makeup\", \"Male\", \"Young\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
