{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d60297-1713-4fa7-a2b9-0603d7b6403b",
   "metadata": {},
   "source": [
    "# Training a classifier\n",
    "We will train a classier for the dataset CIFAR10 that contains images belonging to 10 different classes in two ways:\n",
    "- training a CNN from scratch\n",
    "- finetuning a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f60ee8-d885-4fc1-95a9-a963216fdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1522e6-8c7a-4c17-b885-072653277aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# define batch size\n",
    "batch_size = 4\n",
    "\n",
    "# load train ds\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# load test ds\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc94188-d328-4c1f-906b-669cd4ff9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "img, labels = next(iter(trainloader))\n",
    "\n",
    "plt.imshow(to_pil(torchvision.utils.make_grid(denorm(img))))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d67a7-cdd2-4f9c-a9a7-409a24776d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bbf41e-b2dc-48c7-8058-c330a79157ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN to classify the images\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # first convolutional block\n",
    "        self.conv_block1 = nn.Sequential(nn.Conv2d(3, 6, kernel_size=5),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, 2))\n",
    "        # second convolutional block\n",
    "        self.conv_block2 = nn.Sequential(nn.Conv2d(6, 16, kernel_size=5),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2, 2))\n",
    "        # fully connected blocks\n",
    "        self.fc1 = nn.Sequential(nn.Linear(16 * 5 * 5, 120),\n",
    "                                nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(120, 84),\n",
    "                                 nn.ReLU())\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806a577-a58a-4f63-9e06-b5c6a4cd01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Loss and Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542b1d9-a6fc-46fc-a94d-6d4ee096470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN!\n",
    "# put net into train mode\n",
    "net.train()\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bedaba-bec9-42ed-826c-13d2602a25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to save the model\n",
    "PATH = './res/cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc2aec-1f40-4d90-a378-be06176fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to load the model\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7c54f-c0a0-46e0-a74c-00c639458001",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "## Evaluation Mode (<code>nn.Module.eval()</code>)\n",
    "Evaluation mode is not actually a mechanism to locally disable gradient computation, but it is sometimes confused to be such a mechanism.\n",
    "\n",
    "Functionally, <code>module.eval()</code> (or equivalently <code>module.train(False)</code>) are completely orthogonal to no-grad mode and inference mode. How <code>model.eval()</code> affects your model depends entirely on the specific modules used in your model and whether they define any training-mode specific behavior.\n",
    "\n",
    "You are responsible for calling <code>model.eval()</code> and <code>model.train()</code> if your model relies on modules such as <code>torch.nn.Dropout</code> and <code>torch.nn.BatchNorm2d</code> that may behave differently depending on training mode, for example, to avoid updating your BatchNorm running statistics on validation data.\n",
    "\n",
    "It is recommended that you always use <code>model.train()</code> when training and <code>model.eval()</code> when evaluating your model (validation/testing) even if you aren’t sure your model has training-mode specific behavior, because a module you are using might be updated to behave differently in training and eval modes.\n",
    "\n",
    "## No-grad Mode\n",
    "Computations in no-grad mode behave as if none of the inputs require grad. In other words, computations in no-grad mode are never recorded in the backward graph even if there are inputs that have <code>require_grad=True</code>.\n",
    "\n",
    "Enable no-grad mode when you need to perform operations that should not be recorded by autograd, but you’d still like to use the outputs of these computations in grad mode later. This context manager makes it convenient to disable gradients for a block of code or function without having to temporarily set tensors to have <code>requires_grad=False</code>, and then back to <code>True</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72c945-b750-43ec-9475-bacee71f9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# put net into evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        # put data on correct device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0ec22-7633-41a2-9b38-ba935cbc0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex1: try to get the accuracy for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df71b5-8f1c-4651-be36-d16608007ff0",
   "metadata": {},
   "source": [
    "The classifier was able to correctly classify CIFAR10 with a good accuracy, but we can do much better!\n",
    "HOW?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
